{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "bONB0yDOpegD",
        "RF8TokG_-W7T"
      ],
      "authorship_tag": "ABX9TyPIh6+FQD0uczpEVgNDMeEd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabrielborja/parc_de_montjuic/blob/main/cleaning_scripts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cleaning scripts"
      ],
      "metadata": {
        "id": "lStUu_NOrzIt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libraries"
      ],
      "metadata": {
        "id": "YleVYZS5sBdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upgrade Matplotlib\n",
        "!pip install matplotlib --upgrade\n",
        "#!pip install plotly --upgrade"
      ],
      "metadata": {
        "id": "o6NPkjW-m7mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGeTJjgpsBdW"
      },
      "outputs": [],
      "source": [
        "# Importing python libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "from scipy import stats as st\n",
        "#from geopy.geocoders import Nominatim\n",
        "from ipywidgets import interact"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Data"
      ],
      "metadata": {
        "id": "n_NDy1jtsBdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading data from local drive\n",
        "from google.colab import files\n",
        "uploaded1 = files.upload()"
      ],
      "metadata": {
        "id": "O7uOQYmTsBdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing loaded data from excel to a pandas dataframe\n",
        "import io\n",
        "df1 = pd.read_excel(io.BytesIO(uploaded1['0811_440.xlsx']), sheet_name='Sheet6')"
      ],
      "metadata": {
        "id": "1DSSEUWrsBdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing loaded data from csv to a pandas dataframe\n",
        "#import io\n",
        "#df1 = pd.read_csv(io.BytesIO(uploaded1['202307051425.csv']), sep=',', engine='python', encoding='latin-1')\n",
        "#quotechar='\"', on_bad_lines=False)"
      ],
      "metadata": {
        "id": "sW7oVve_ggcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modifying columns to lower case\n",
        "df1.rename(columns={i:i.lower() for i in df1.columns}, inplace=True)"
      ],
      "metadata": {
        "id": "kGPBKIADjT94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.rename(columns={'operator_in_commercial_name':'operator_in'}, inplace=True)"
      ],
      "metadata": {
        "id": "eqIYosRidcMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking dataframe info\n",
        "pd.DataFrame(df1.info())"
      ],
      "metadata": {
        "id": "3bYk72_tfjYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning Data"
      ],
      "metadata": {
        "id": "B4lTGJ3exux6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pd.concat(pd.DataFrame(df1.dtypes),df1.count())\n",
        "df1.dtypes\n",
        "#pd.concat(df1.dtypes, df1.count())\n",
        "#df1.count()\n",
        "#pd.concat()"
      ],
      "metadata": {
        "id": "CuxwzcnHgXus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parsing object column to datetime\n",
        "# format ['m%/%d/%Y %I:%M:%S %p','%Y-%m-%d %H:%M:%S.%f',]\n",
        "\n",
        "date_col = 'period' #-> Change to the desired column\n",
        "def parse_datetime(date_col):\n",
        "  df1[date_col] = pd.to_datetime(df1[date_col], format='%d.%m.%Y %H.%M.%S')\n",
        "\n",
        "parse_datetime(date_col)"
      ],
      "metadata": {
        "id": "S6bHev7HPrSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['period'] = df1['period'].astype('str')\n",
        "df1 = df1[df1['category']=='Ratio']"
      ],
      "metadata": {
        "id": "qo_5lu0ppVFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting year, month, day of the week, hour and date categories\n",
        "\n",
        "date_col = 'inserted_date' #-> Change to the desired column\n",
        "def extract_datetime(df, date_col):\n",
        "  df = df.assign(year = df[date_col].dt.year,\n",
        "                 month = df[date_col].dt.month_name(),\n",
        "                 weeknum = df[date_col].dt.isocalendar().week,\n",
        "                 week_of_year = 'w' + df[date_col].dt.isocalendar().week.astype(str),\n",
        "                 day_of_week = df[date_col].dt.day_name(),\n",
        "                 hour = df[date_col].dt.hour.astype(str) + 'h',\n",
        "                 hour_of_day = df[date_col].dt.hour)\n",
        "  return df\n",
        "\n",
        "df1 = extract_datetime(df1, date_col)"
      ],
      "metadata": {
        "id": "IQJGJt9NrOaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting latitud and longitud from city names\n",
        "def extract_lat_and_lon(df):\n",
        "  geolocator = Nominatim(user_agent=\"MyApp\")\n",
        "  cities = sorted([i for i in set(df1['municipality'])])\n",
        "  ci_lat = {}\n",
        "  ci_lon = {}\n",
        "  for i in cities:\n",
        "    location = geolocator.geocode(i)\n",
        "    ci_lat.update({i:location.latitude})\n",
        "    ci_lon.update({i:location.longitude})\n",
        "  #ci_lat = {i: geolocator.geocode(i).latitude for i in cities}\n",
        "  #ci_lon = {i: geolocator.geocode(i).longitude for i in cities}\n",
        "  df = df.assign(lat = df['municipality'].replace(to_replace=ci_lat),\n",
        "                 lon = df['municipality'].replace(to_replace=ci_lon)\n",
        "                 )\n",
        "  return df\n",
        "  #return {i: (geolocator.geocode(i).latitude, geolocator.geocode(i).longitude) for i in my_list}\n",
        "\n",
        "df1 = extract_lat_and_lon(df1)\n",
        "df1.tail()"
      ],
      "metadata": {
        "id": "6OLxH7rTzABh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning invalid orgnum\n",
        "org_col = 'customer_orgnumber' #-> Change to the desired column\n",
        "def check_valid_org_num(df):\n",
        "  df = df.assign(org_check = np.where(df['org_col'].isnull(), 'Wrong',\n",
        "                             np.where(df['org_col'].str.len()>9, 'Wrong',\n",
        "                             np.where(df['org_col'].str.match(r'\\d{9}'),'Valid','Wrong'))))\n",
        "  return df\n",
        "\n",
        "df1 = check_valid_org_num(df1)"
      ],
      "metadata": {
        "id": "HjBVQ-SxXmC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flattening list of list and extracting unique valid IDs from column\n",
        "def extract_valid_ids(df, column_name):\n",
        "  temp1 = [list(json.loads(i).items()) for i in df[column_name]]\n",
        "  temp2 = [i for x in temp1 for i in x]\n",
        "  temp3 = [i[1] for i in temp2 if i[0] == 'naviIdIfMinBedrift']\n",
        "  flat = list(set(temp3))\n",
        "  f_df = pd.DataFrame(flat, columns=['valid_id']).sort_values(by='valid_id').reset_index(drop=True)\n",
        "  return f_df\n",
        "  #flat = [i for x in temp1 for i in x]\n",
        "  #set(flat)\n",
        "\n",
        "df2 = extract_valid_ids(df1,'custom_dimensions')\n",
        "df2.head()"
      ],
      "metadata": {
        "id": "kilsD4mR3kbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforming nace code"
      ],
      "metadata": {
        "id": "alye0oMo-MXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing common data cleaning tasks\n",
        "df1 = df1.assign(county = df1['county'].str[:16])\n",
        "#df1 = df1.assign(market_nace_main_desc = df1['market_nace_main_desc'].str[:20])\n",
        "#df1.rename( columns={'client_country_or_region':'country'}, inplace=True)\n",
        "#df1 = df1.assign(terminal_brand = df1['terminal_brand'].str[:16])"
      ],
      "metadata": {
        "id": "CU4FtNhjY6Y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning brand preference\n",
        "df1 = df1.assign(brand = np.where(df1['terminal_name'].str.contains('iPhone'),'Apple',\n",
        "                                  np.where(df1['terminal_name'].str.contains('Samsung'),'Samsung', 'Other')))"
      ],
      "metadata": {
        "id": "evwHNJ0CNuYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating categorical orgnum column\n",
        "df1 = df1.assign(org_num = 'ORG' + df1['organization_number'].astype(str))"
      ],
      "metadata": {
        "id": "wfrUWtgnQGSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating time of day column\n",
        "df1 = df1.assign(time_of_day = np.where(df1['hr']<=11,'Morning',np.where(df1['hr']<=14,'Lunch','Afternoon')))"
      ],
      "metadata": {
        "id": "ex3vV1iaq1Il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Customizing terminal categories\n",
        "df1 = df1.assign(product_choice = np.where(df1['product_name'].str.contains('iPhone 11'),'iPhone 11',\n",
        "                                           np.where(df1['product_name'].str.contains('iPhone 12'),'iPhone 12',\n",
        "                                                    np.where(df1['product_name'].str.contains('iPhone 13'),'iPhone 13',\n",
        "                                                             np.where(df1['product_name'].str.contains('iPhone 14'),'iPhone 14',\n",
        "                                                                      np.where(df1['product_name'].str.contains('OnePlus'),'OnePlus',\n",
        "                                                                               'Samsung'))))))"
      ],
      "metadata": {
        "id": "0CWjDUwKwD8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[i for i in df1.select_dtypes(include=['float64','int64']).copy().columns.tolist() if '_id' not in i]"
      ],
      "metadata": {
        "id": "g0aFLdjBZOec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"-\".join([i[0:2] for i in df1['nace_main'][0].split(' ')])"
      ],
      "metadata": {
        "id": "EfnC1YGI3Kq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1[df1['org_check']=='Valid'][['inserted_date','customer_orgnumber','org_check']].reset_index()"
      ],
      "metadata": {
        "id": "I3rzGwUIOUvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Temp1: Slicing dataframe\n",
        "df2 = df1[['orderid','statustext','username','listname','inserted_date','customer_orgnumber','customer_company',\n",
        "'customer_phone','customer_cellphone','customer_email','accept_date','productname','nummer som skal benytte',\n",
        "'orderproductsquantity','productquantity','year','month','weeknum','day','hour','hr','org_check']].copy()\n",
        "df2 = df2[df2['org_check']=='Valid'].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "B--ctk6iaz7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforming survey answers to categories\n",
        "def trans_column(df, col_x, col_name):\n",
        "  cho_dict = {1:'Low',2:'Low',3:'Medium',4:'Medium',5:'High',6:'High',7:'Vet Ikke'}\n",
        "  #cho_dict = {1:'Ja',2:'Nei',3:'Vet Ikke'}\n",
        "  #cho_dict = {1:'Jeg er over snittet',2:'Jeg holder meg oppdatert',3:'Jeg er ikke sÃ¦rlig opptat'}\n",
        "  df = df.assign(prop = df[col_x].replace(to_replace=cho_dict))\n",
        "  df.rename(columns={'prop':col_name}, inplace= True)\n",
        "  return df\n",
        "  #return pd.DataFrame(df.value_counts(subset=col_x, normalize=True).sort_index()).reset_index().rename(columns={0:'Proportion'})\n",
        "\n",
        "df1 = trans_column(df1, 'q9', 'q9_cat')\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "t5-8rB_RvH0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Categories companies by size\n",
        "def loy_stage(df, col_x):\n",
        "    con_1 = [df[col_x]<90,df[col_x]<180,df[col_x]<540,df[col_x]<730,df[col_x]>=730]\n",
        "    cho_1 = ['onbo','adop','deve','reten','loy']\n",
        "    df = df.assign(loyalty_stage = np.select(con_1, cho_1, df[col_x]))\n",
        "    return df\n",
        "\n",
        "df1 = loy_stage(df1, 'lifetime_days')\n",
        "#df1_tes['company_size']"
      ],
      "metadata": {
        "id": "YbG_XllDXpjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Categories companies by size\n",
        "def com_size(df, col_x, seg_type):\n",
        "  \"\"\"seg_type: simple or deeper\"\"\"\n",
        "  if seg_type == 'simple':\n",
        "    con_1 = [df[col_x]==0,df[col_x]<10,df[col_x]<20,df[col_x]<100,df[col_x]>=100]\n",
        "    cho_1 = ['Unknown','01_09_SoHo','10_19_Small','20_99_Medium','100+_Enterprise']\n",
        "    df = df.assign(company_size = np.select(con_1, cho_1, df[col_x]))\n",
        "    return df\n",
        "  elif seg_type == 'deeper':\n",
        "    con_1 = [df[col_x]==0,df[col_x]==1,df[col_x]==2,df[col_x]<6,df[col_x]<10,df[col_x]<20,df[col_x]>=20]\n",
        "    cho_1 = ['Unknown','01_abo','02_abo','03-05_abo','06-09_abo','10-19_abo','20+_abo']\n",
        "    df = df.assign(company_size = np.select(con_1, cho_1, df[col_x]))\n",
        "    return df\n",
        "\n",
        "df1 = com_size(df1, 'subs_pr_customer_eop', 'deeper')\n",
        "#df1_tes['company_size']"
      ],
      "metadata": {
        "id": "_2YYZvnmlGCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouping by category and aggregating by statistical metrics, mean, std, median, skew\n",
        "def group_stats(cat_1, col_x):\n",
        "  df = df1.copy()\n",
        "  df = df[df[col_x]!=7][[cat_1, col_x]].reset_index(drop=True) #Dropping 7 = 'Vet Ikke'\n",
        "  # Option 1\n",
        "  #df = df.groupby(by=[cat_1]).describe().reset_index()\n",
        "  #df.columns = df.columns.droplevel(level=0)\n",
        "  #df.columns.values[[0, 1]] = [cat_1, cat_2]\n",
        "  #df.columns.values[[0, 0]] = [cat_1]\n",
        "  #df.index.name = col_x\n",
        "  #return df\n",
        "\n",
        "  #----------------\n",
        "  # Option 2\n",
        "  df = df.groupby(by=[cat_1]).agg(count=(col_x,'count'),nunique=(col_x,'nunique'), min=(col_x,'min'), max=(col_x,'max'),\n",
        "                                  mean=(col_x,'mean'), median=(col_x,'median'), std=(col_x,'std'),\n",
        "                                  var=(col_x,'var'), skew=(col_x,'skew')).reset_index()\n",
        "  df.columns.values[[0, 0]] = [cat_1]\n",
        "  return df\n",
        "  #return df.groupby([cat])[col_x].agg(np.unique(col_x,axis=1))\n",
        "gr_st = group_stats('company_size','q9')\n",
        "gr_st\n",
        "#gr_st.loc[:,['nace','skew']]"
      ],
      "metadata": {
        "id": "pbgt0uAvFd-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouping by category and proportion of survey\n",
        "def group_proportion(cat_1, col_f, col_x):\n",
        "  df = df1.copy()\n",
        "  df = df[df[col_f]!=7][[cat_1, col_x]].reset_index(drop=True) #Dropping 7 = 'Vet Ikke'\n",
        "  df = df.assign(high = np.where(df[col_x]=='High',1,0),\n",
        "                 medium = np.where(df[col_x]=='Medium',1,0),\n",
        "                 low = np.where(df[col_x]=='Low',1,0))\n",
        "  df = df.groupby(by=[cat_1]).agg(count=(col_x,'count'), sum_high =('high','sum'),\n",
        "                                  sum_medium=('medium','sum'),sum_low=('low','sum')).reset_index()\n",
        "  df = df.assign(high_prop = df['sum_high']/df['count'], medium_prop = df['sum_medium']/df['count'],\n",
        "                 low_prop = df['sum_low']/df['count'])\n",
        "  df.columns.values[[0]] = [cat_1]\n",
        "  return df\n",
        "gr_st = group_proportion('company_size', 'q9','q9_cat')\n",
        "gr_st\n",
        "#gr_st.loc[:,['nace','skew']]"
      ],
      "metadata": {
        "id": "HRfcRnCn33MV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting categorical and numeric columns for EDA\n",
        "custom_list_1 = df1.select_dtypes(include=['object']).copy().columns.tolist()\n",
        "custom_list_2 = [i for i in df1.select_dtypes(include=['float64','int64']).copy().columns.tolist() ]#if '_id' not in i]"
      ],
      "metadata": {
        "id": "pRuAqjseVzTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring Data"
      ],
      "metadata": {
        "id": "0xEkdt6DUMnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying less rows in aggregations\n",
        "pd.options.display.max_rows = 26\n",
        "pd.options.display.min_rows = 10"
      ],
      "metadata": {
        "id": "Ltt9IWJgGLnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploring list of categorical columns with value counts\n",
        "#segm_list = ['Smartphone','Mobile broadband','Machine to machine']\n",
        "@interact(Column_name=custom_list_1, Percentage=[True, False])\n",
        "def explore_value_counts(Column_name, Percentage):\n",
        "  if Percentage == True:\n",
        "    df = df1.value_counts(subset=[Column_name], normalize=Percentage, dropna=False).reset_index(name='percent')\n",
        "    df = df.assign(percent = round(df['percent'],6)*100)\n",
        "    #df = df.assign(cum_perc = df['percent'].cumsum())\n",
        "    df = df.assign(percent = df['percent'].round(2).astype(str) + '%')\n",
        "    #df = df.assign(cum_perc = df['cum_perc'].round(2).astype(str) + '%')\n",
        "  else:\n",
        "    df = df1.value_counts(subset=[Column_name], normalize=Percentage, dropna=False).reset_index(name='events')\n",
        "    #df = df.sort_values(by=['events']).reset_index(drop=True)\n",
        "  return df"
      ],
      "metadata": {
        "id": "UGUH4IcP172y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploring list of categorical columns with value counts\n",
        "@interact(Categories=custom_list_1, Column_name=custom_list_2, Aggregate=['count','nunique','sum','mean','median','max','min'])\n",
        "def explore_numeric_columns(Categories, Column_name, Aggregate):\n",
        "  df = df1.groupby(by=Categories).agg(value=(Column_name,Aggregate)).reset_index()\n",
        "  df.rename(columns={'value':Column_name}, inplace=True)\n",
        "  df = df.sort_values(by=[Column_name],ascending=False).reset_index(drop=True)\n",
        "  return df"
      ],
      "metadata": {
        "id": "Yotbkx7R-0Zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Describing categorical columns with statistical parameters\n",
        "@interact(Categories=custom_list_1, Column_name=custom_list_2, Order_by=['count','mean','std','total'])\n",
        "def describe_columns(Categories, Column_name, Order_by):\n",
        "  df = df1.groupby(by=[Categories])[Column_name].describe().reset_index()\n",
        "  df = df.assign(total = round(df['count']*df['mean'],2))\n",
        "  #df.rename(columns={Categories:Column_name}, inplace=True)\n",
        "  df = df.sort_values(by=[Order_by],ascending=False).reset_index(drop=True)\n",
        "  #df = df[df['mean']<=30]\n",
        "  return df"
      ],
      "metadata": {
        "id": "hjws-2Xs-37E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting categorical columns with numeric columns\n",
        "agg_list = ['sum','mean','median','max','min','nunique','count']\n",
        "#segm_list = ['Smartphone','Mobile broadband','Machine to machine']\n",
        "@interact(Categories=['discount_description'], Column_name=custom_list_2, Aggregate=agg_list, Decimals=['%.f','%.2f'])\n",
        "def visualize_two_columns(Categories, Column_name, Aggregate, Decimals):\n",
        "  df = df1.groupby(by=[Categories]).agg(value=(Column_name,Aggregate)).reset_index()\n",
        "  #df1.value_counts(subset=[Categories, Column_name], normalize=True).reset_index(name='perc')\n",
        "  df.rename(columns={'value':Column_name}, inplace=True)\n",
        "  #df = df.sort_values(by=[Column_name],ascending=False).reset_index(drop=True)\n",
        "  #return df\n",
        "  fig_x, axes = plt.subplots(1, 1, figsize=(9.0, 5.5))\n",
        "  axes.set_title(f'{Column_name} by {Categories}')\n",
        "  sns.barplot(x=Categories, y=Column_name, data=df, estimator=Aggregate, palette=['#FFC600','#0080FF'], ax=axes)\n",
        "  for i in axes.containers:\n",
        "    axes.bar_label(i,fmt=Decimals)\n",
        "  #x_dates = df['discount_description'].dt.strftime('%Y-%m-%d').unique()\n",
        "  #axes.set_xticklabels(labels=x_dates, rotation=45, ha='right')\n",
        "  #plt.legend(title='Is_Loyal', bbox_to_anchor=(1.15, 1), loc=2, borderaxespad=0.)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "jZAXJd5tQR2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing histogram of numeric columns dynamically\n",
        "segm_list = ['Smartphone','Mobile broadband','Machine to machine']\n",
        "dis_list_1 =['count', 'frequency','probability', 'proportion', 'percent', 'density']\n",
        "@interact(Family=segm_list, Column=custom_list_2[2:], Graph_type=dis_list_1)\n",
        "def plot_histogram(Family, Column, Graph_type):\n",
        "  df = df1[df1['product_family']==Family].reset_index(drop=True).copy()\n",
        "  Q1 = df[Column].quantile(0.25)\n",
        "  Q3 = df[Column].quantile(0.75)\n",
        "  IQR = Q3 - Q1\n",
        "  df = df[(df[Column]>(Q1-1.5*IQR)) & (df[Column]<(Q3+1.5*IQR))].reset_index(drop=True)\n",
        "  fig_x, axes = plt.subplots(1, 1, figsize=(7.5, 3.5))\n",
        "  axes.set_title(f'{Family}: {Graph_type} - {Column}')\n",
        "  sns.histplot(x=Column, data=df, hue='loyalty_flag', stat=Graph_type, bins=15,\n",
        "               multiple='stack', palette={'Yes':'green','No':'#e49444'}, ax=axes)\n",
        "  for i in axes.containers:\n",
        "    axes.bar_label(i,fmt='%.2f')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "ccW7l0AJH2M-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing distribution of numeric columns dynamically\n",
        "segm_list = ['Smartphone','Mobile broadband','Machine to machine']\n",
        "dis_list_2 =['hist', 'kde','ecdf']\n",
        "@interact(Family=segm_list, Column=custom_list_2[2:], Graph_type=dis_list_2, Log_sc=[False,True])\n",
        "def plot_distribution(Family, Column, Graph_type, Log_sc):\n",
        "  df = df1[df1['product_family']==Family].reset_index(drop=True).copy()\n",
        "  Q1 = df[Column].quantile(0.25)\n",
        "  Q3 = df[Column].quantile(0.75)\n",
        "  IQR = Q3 - Q1\n",
        "  df = df[(df[Column]>(Q1-1.5*IQR)) & (df[Column]<(Q3+1.5*IQR))].reset_index(drop=True)\n",
        "  #sns.set(rc={'figure.figsize':(10,5)})\n",
        "  sns.displot(x=Column, data=df, hue='loyalty_flag', kind=Graph_type, log_scale=Log_sc, #multiple='stack',\n",
        "              palette={'Yes':'green','No':'#e49444'}, height=4.5, aspect=2)\n",
        "  plt.title(f'{Family} - {Column}')\n",
        "  plt.axhline(y=0.5, color='red', ls='--')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "UtqoJoogSJ6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing distribution of numeric columns dynamically\n",
        "segm_list = ['Smartphone','Mobile broadband','Machine to machine']\n",
        "@interact(Family=segm_list, X_col=custom_list_2[2:], Y_col=custom_list_1)\n",
        "def plot_boxplot(Family, X_col, Y_col):\n",
        "  df = df1[df1['product_family']==Family].reset_index(drop=True).copy()\n",
        "  Q1 = df[X_col].quantile(0.25)\n",
        "  Q3 = df[X_col].quantile(0.75)\n",
        "  IQR = Q3 - Q1\n",
        "  df = df[(df[X_col]>(Q1-1.5*IQR)) & (df[X_col]<(Q3+1.5*IQR))].reset_index(drop=True)\n",
        "  #sns.set(rc={'figure.figsize':(10,5)})\n",
        "  sns.boxplot(x=X_col, y=Y_col, data=df, hue='loyalty_flag', palette={'Yes':'green','No':'#e49444'})\n",
        "  plt.title(f'{X_col} - {Y_col}')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "AiiJ9bYYDayk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting pair plot of numeri variables\n",
        "segm_list = ['Smartphone','Mobile broadband','Machine to machine']\n",
        "hue_list = ['loyalty_flag']\n",
        "@interact(Family=segm_list, Column=custom_list_2[2:], Flag=hue_list)\n",
        "def plot_pairplot(Family, Column, Flag):\n",
        "  df = df1[df1['product_family']==Family].reset_index(drop=True).copy()\n",
        "  df = df[['product_family','loyalty_flag','lifetime_days','mb_total_l3m_avg','voice_total_l3m_avg','subscriber_profit']].copy()\n",
        "  sns.pairplot(data=df, hue=Flag)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "2ww1YmOaAovG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing scatterplot of numeric columns dynamically\n",
        "@interact(Column=custom_list_2)\n",
        "def visualize_numeric(Column):\n",
        "  # 'count', 'frequency','probability', 'proportion', 'percent', 'density'\n",
        "  Q1 = df1[Column].quantile(0.25)\n",
        "  Q3 = df1[Column].quantile(0.75)\n",
        "  IQR = Q3 - Q1\n",
        "  df = df1[(df1[Column]>(Q1-1.5*IQR)) & (df1[Column]<(Q3+1.5*IQR))].reset_index(drop=True)\n",
        "  #sns.set(rc={'figure.figsize':(10,5)})\n",
        "  sns.scatterplot(x='lifetime_days', y=Column, data=df, hue='loyalty_flag', style='loyalty_flag') #color='green' #binwidth=2\n",
        "  plt.title(f'Histogram - {Column}')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "tUGUyBturhuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing time columns\n",
        "@interact(Time_column=['month','week_of_year','day_of_week','hour'])\n",
        "def visualize_time_dimension(Time_column):\n",
        "  sns.catplot(x=Time_column, data=df1, kind='count', color='#0080FF', height=5, aspect=2.0,\n",
        "              order=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
        "              #order=['0h','1h','2h','3h','4h','5h','6h','7h','8h','9h','10h','11h','12h',\n",
        "              #'13h','14h','15h','16h','17h','18h','19h','20h','21h','22h','23h']) #'#0080FF', '#070707', '#454545'\n",
        "  )\n",
        "  plt.title(f'Events by {Time_column}')\n",
        "  #plt.axhline(y=43, color='red', label='avg_week')\n",
        "  #plt.legend(bbox_to_anchor = (1.1, 1), loc = 'upper center')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "tL7ZieQNslIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Interacting with list of columns\n",
        "@interact(Column_name = custom_list_1, Variable = custom_list_2)\n",
        "def visualize_nace(Nace, Variable):\n",
        "  df = df1[df1['market_nace_main_desc']==Nace].copy()\n",
        "  df = df.groupby(by=['market_nace_main_desc','county']).agg(avg = (Variable,'mean')).reset_index()\n",
        "  fig_x, axes = plt.subplots(1, 1, figsize=(7.5, 5.5))\n",
        "  axes.set_title(f'{Nace}: {Variable}')\n",
        "  sns.barplot(x='market_nace_main_desc', y='avg', data=df, hue='county', palette='tab20', ax=axes)\n",
        "  plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "dIrCE0p2SpVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df1[df1['categories'] != 'period']"
      ],
      "metadata": {
        "id": "tInb-fdMB4VY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "metadata": {
        "id": "XrlgCrEmCaRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting a horizontal barchart\n",
        "def plot_horizontal_barchat(index, value_1, value_2):\n",
        "  df = df1[(df1[value_1] > 0.2) & (df1['categories'] != 'arpu')].set_index(index)\n",
        "  fig_x, axes = plt.subplots(1, 1, figsize=(6,6))\n",
        "  axes.set_title(f'ARPU - Fordel 440 vs. Rest of B2B')\n",
        "  df.plot.barh(y=[value_1, value_2], ax=axes)\n",
        "  for i in axes.containers:\n",
        "    axes.bar_label(i,fmt='%.2f')\n",
        "  plt.rcdefaults()\n",
        "  plt.rcParams.update({'font.size': 8})\n",
        "  plt.show()\n",
        "plot_horizontal_barchat(index='categories', value_1 = 'rest of b2b', value_2='fordel 440')"
      ],
      "metadata": {
        "id": "zZvf1AzNBuTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1[df1['arpu'] > 0.05].set_index('categories')"
      ],
      "metadata": {
        "id": "bwfvprLuGzZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.drop(['period','category'], axis=1).plot.bar(x='discount_description', y='sum_tvillingsim', palette=[''])\n",
        "plt.leyend()"
      ],
      "metadata": {
        "id": "Jc7RXrs3_C7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggregating Data"
      ],
      "metadata": {
        "id": "bONB0yDOpegD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting columns for aggregation\n",
        "custom_list_2 = ['', '', '', ''] # => Add column names for slicing here."
      ],
      "metadata": {
        "id": "NNoCs4zwplwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main data aggregation\n",
        "df1_a = df1.groupby(by=custom_list_2, dropna=False).agg(CHURN_COUNT = ('CUSTOMER_ID', 'count')).reset_index() # => Note: Dropna=False to avoid dropping data if group keys contain NA values."
      ],
      "metadata": {
        "id": "fkRYz8ZiULYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating list of aggregated fields\n",
        "df1_list = [(pd.DataFrame(df1[i].value_counts(dropna=False))) for i in custom_list_1]"
      ],
      "metadata": {
        "id": "0V36296QXe5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transposing dataframe\n",
        "df1_tra = df1.set_index(['discount_description']).T\n",
        "df1_tra"
      ],
      "metadata": {
        "id": "WWVZUfuOLamz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking standard deviation of dataset\n",
        "df1.describe().loc['std'].reset_index().sort_values(by='std', ascending=False).reset_index(drop=True).head(15)"
      ],
      "metadata": {
        "id": "MWRvhitVT--V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exporting results to local drive"
      ],
      "metadata": {
        "id": "RF8TokG_-W7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting main excel file\n",
        "with pd.ExcelWriter('script_05.xlsx', engine='openpyxl') as writer:\n",
        "  df1_tra.to_excel(writer, sheet_name='Sheet1', index=True)\n",
        "files.download('script_05.xlsx')"
      ],
      "metadata": {
        "id": "sPlkPCjpeybu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting list of excel sheets\n",
        "with pd.ExcelWriter('Script_202208221130.xlsx', engine='openpyxl') as writer:\n",
        "  for i in range(len(df1_list)-1):\n",
        "    df1_list[i].to_excel(writer, sheet_name=f'{df1_list[i].columns[0]}', index=True)\n",
        "files.download('Script_202208221130.xlsx')"
      ],
      "metadata": {
        "id": "ZA02I_Wf-W7T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}