{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "lStUu_NOrzIt",
        "YleVYZS5sBdW",
        "n_NDy1jtsBdX",
        "0xEkdt6DUMnG",
        "bONB0yDOpegD",
        "RF8TokG_-W7T"
      ],
      "authorship_tag": "ABX9TyNk9XH846CFCMihniWwCV/j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabrielborja/parc_de_montjuic/blob/main/cleaning_scripts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cleaning scripts"
      ],
      "metadata": {
        "id": "lStUu_NOrzIt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libraries"
      ],
      "metadata": {
        "id": "YleVYZS5sBdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upgrade Matplotlib\n",
        "!pip install matplotlib --upgrade\n",
        "#!pip install plotly --upgrade"
      ],
      "metadata": {
        "id": "o6NPkjW-m7mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGeTJjgpsBdW"
      },
      "outputs": [],
      "source": [
        "# Importing python libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "from ipywidgets import interact"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Data"
      ],
      "metadata": {
        "id": "n_NDy1jtsBdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading data from local drive\n",
        "from google.colab import files\n",
        "uploaded1 = files.upload()"
      ],
      "metadata": {
        "id": "O7uOQYmTsBdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing loaded data from excel to a pandas dataframe\n",
        "#import io\n",
        "#df1 = pd.read_excel(io.BytesIO(uploaded1['2023_04_12_data.xlsx']))"
      ],
      "metadata": {
        "id": "1DSSEUWrsBdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing loaded data from csv to a pandas dataframe\n",
        "import io\n",
        "df1 = pd.read_csv(io.BytesIO(uploaded1['mdrift.csv']), sep=';', engine='python')#, encoding='latin-1')\n",
        "#quotechar='\"', on_bad_lines=False)"
      ],
      "metadata": {
        "id": "sW7oVve_ggcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modifying columns to lower case\n",
        "df1.rename(columns={i:i.lower() for i in df1.columns}, inplace=True)"
      ],
      "metadata": {
        "id": "kGPBKIADjT94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.rename(columns={'operator_in_commercial_name':'operator_in'}, inplace=True)"
      ],
      "metadata": {
        "id": "eqIYosRidcMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking dataframe info\n",
        "pd.DataFrame(df1.info())"
      ],
      "metadata": {
        "id": "3bYk72_tfjYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning Data"
      ],
      "metadata": {
        "id": "B4lTGJ3exux6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pd.concat(pd.DataFrame(df1.dtypes),df1.count())\n",
        "df1.dtypes\n",
        "#pd.concat(df1.dtypes, df1.count())\n",
        "#df1.count()\n",
        "#pd.concat()"
      ],
      "metadata": {
        "id": "CuxwzcnHgXus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parsing object column to datetime\n",
        "#df1['inserted_date'] = pd.to_datetime(df1['inserted_date']) #format='m%/%d/%Y %I:%M:%S %p')\n",
        "\n",
        "date_col = 'timestamp' #-> Change to the desired column\n",
        "def parse_datetime(date_col):\n",
        "  df1[date_col] = pd.to_datetime(df1[date_col], format='%Y-%m-%d %H:%M:%S.%f')\n",
        "\n",
        "parse_datetime(date_col)"
      ],
      "metadata": {
        "id": "S6bHev7HPrSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting year, month, day of the week, hour and date categories\n",
        "\n",
        "date_col = 'timestamp' #-> Change to the desired column\n",
        "def extract_datetime(df, date_col):\n",
        "  df = df.assign(year = df[date_col].dt.year,\n",
        "                 month = df[date_col].dt.month_name(),\n",
        "                 weeknum = df[date_col].dt.isocalendar().week,\n",
        "                 week_of_year = 'w' + df[date_col].dt.isocalendar().week.astype(str),\n",
        "                 day_of_week = df[date_col].dt.day_name(),\n",
        "                 hour = df[date_col].dt.hour.astype(str) + 'h',\n",
        "                 hour_of_day = df[date_col].dt.hour)\n",
        "  return df\n",
        "\n",
        "df1 = extract_datetime(df1, date_col)"
      ],
      "metadata": {
        "id": "IQJGJt9NrOaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning invalid orgnum\n",
        "\n",
        "org_col = 'customer_orgnumber' #-> Change to the desired column\n",
        "def check_valid_org_num(df):\n",
        "  df = df.assign(org_check = np.where(df['org_col'].isnull(), 'Wrong',\n",
        "                             np.where(df['org_col'].str.len()>9, 'Wrong',\n",
        "                             np.where(df['org_col'].str.match(r'\\d{9}'),'Valid','Wrong'))))\n",
        "  return df\n",
        "\n",
        "df1 = check_valid_org_num(df1)"
      ],
      "metadata": {
        "id": "HjBVQ-SxXmC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforming nace code\n",
        "df1 = df1.assign(market_nace_main_desc = df1['market_nace_main_desc'].str[:22])"
      ],
      "metadata": {
        "id": "alye0oMo-MXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing county\n",
        "df1 = df1.assign(county = df1['county'].str[:16])"
      ],
      "metadata": {
        "id": "CU4FtNhjY6Y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning brand preference\n",
        "df1 = df1.assign(brand = np.where(df1['product_name'].str.contains('iPhone'),'Apple','Samsung'))"
      ],
      "metadata": {
        "id": "evwHNJ0CNuYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating categorical orgnum column\n",
        "df1 = df1.assign(org_num = 'ORG' + df1['organization_number'].astype(str))"
      ],
      "metadata": {
        "id": "wfrUWtgnQGSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating time of day column\n",
        "df1 = df1.assign(time_of_day = np.where(df1['hr']<=11,'Morning',np.where(df1['hr']<=14,'Lunch','Afternoon')))"
      ],
      "metadata": {
        "id": "ex3vV1iaq1Il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Customizing terminal categories\n",
        "df1 = df1.assign(product_choice = np.where(df1['product_name'].str.contains('iPhone 11'),'iPhone 11',\n",
        "                                           np.where(df1['product_name'].str.contains('iPhone 12'),'iPhone 12',\n",
        "                                                    np.where(df1['product_name'].str.contains('iPhone 13'),'iPhone 13',\n",
        "                                                             np.where(df1['product_name'].str.contains('iPhone 14'),'iPhone 14',\n",
        "                                                                      np.where(df1['product_name'].str.contains('OnePlus'),'OnePlus',\n",
        "                                                                               'Samsung'))))))"
      ],
      "metadata": {
        "id": "0CWjDUwKwD8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the dataframe tail\n",
        "df1.tail(1)"
      ],
      "metadata": {
        "id": "cpao-slIUtMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting categorical and numeric columns for EDA\n",
        "custom_list_1 = df1.select_dtypes(include=['object']).copy().columns.tolist()\n",
        "custom_list_2 = [i for i in df1.select_dtypes(include=['float64','int64']).copy().columns.tolist() if '_id' not in i]"
      ],
      "metadata": {
        "id": "pRuAqjseVzTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[i for i in df1.select_dtypes(include=['float64','int64']).copy().columns.tolist() if '_id' not in i]"
      ],
      "metadata": {
        "id": "g0aFLdjBZOec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"-\".join([i[0:2] for i in df1['nace_main'][0].split(' ')])"
      ],
      "metadata": {
        "id": "EfnC1YGI3Kq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1[df1['org_check']=='Valid'][['inserted_date','customer_orgnumber','org_check']].reset_index()"
      ],
      "metadata": {
        "id": "I3rzGwUIOUvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Temp1: Slicing dataframe \n",
        "df2 = df1[['orderid','statustext','username','listname','inserted_date','customer_orgnumber','customer_company',\n",
        "'customer_phone','customer_cellphone','customer_email','accept_date','productname','nummer som skal benytte',\n",
        "'orderproductsquantity','productquantity','year','month','weeknum','day','hour','hr','org_check']].copy()\n",
        "df2 = df2[df2['org_check']=='Valid'].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "B--ctk6iaz7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting keys from column and flattening list of list to obtain unique set of keys.\n",
        "temp1 = [list(json.loads(i).keys()) for i in df1['custom_dimensions']]\n",
        "flat = [i for x in temp1 for i in x]\n",
        "set(flat)"
      ],
      "metadata": {
        "id": "kilsD4mR3kbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring Data"
      ],
      "metadata": {
        "id": "0xEkdt6DUMnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploring list of categorical columns with value counts\n",
        "@interact(Column_name=custom_list_1, Percentage=[True, False])\n",
        "def explore_value_counts(Column_name, Percentage):\n",
        "  if Percentage == True:\n",
        "    df = df1.value_counts(subset=[Column_name], normalize=Percentage, dropna=False).reset_index(name='percent')\n",
        "    df = df.assign(percent = round(df['percent'],2)*100)\n",
        "    df = df.assign(percent = df['percent'].round(2).astype(str) + '%')\n",
        "  else:\n",
        "    df = df1.value_counts(subset=[Column_name], normalize=Percentage, dropna=False).reset_index(name='events')\n",
        "    #df = df.sort_values(by=['events']).reset_index(drop=True)\n",
        "  return df"
      ],
      "metadata": {
        "id": "UGUH4IcP172y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploring list of categorical columns with value counts\n",
        "@interact(Categories=custom_list_1, Column_name=custom_list_2, Aggregate=['count','nunique','sum','mean','max','min'])\n",
        "def explore_numeric_columns(Categories, Column_name, Aggregate):\n",
        "  df = df1.groupby(by=Categories).agg(value=(Column_name,Aggregate)).reset_index()\n",
        "  df.rename(columns={'value':Column_name}, inplace=True)\n",
        "  df = df.sort_values(by=[Column_name],ascending=False).reset_index(drop=True)\n",
        "  return df"
      ],
      "metadata": {
        "id": "Yotbkx7R-0Zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing numeric columns dynamically\n",
        "@interact(Numeric_column=reversed(custom_list_2))\n",
        "def visualize_numeric(Numeric_column):\n",
        "  # 'count', 'frequency','probability', 'proportion', 'percent', 'density'\n",
        "  sns.set(rc={'figure.figsize':(10,5)})\n",
        "  sns.histplot(x=Numeric_column, data=df1, stat='count',color='gold', binwidth=2) #color='green'\n",
        "  plt.title(f'Histogram - {Numeric_column}')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "-H7ASpaedvXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing time columns\n",
        "@interact(Time_column=['month','week_of_year','day_of_week','hour'])\n",
        "def visualize_time_dimension(Time_column):\n",
        "  sns.catplot(x=Time_column, data=df1, kind='count', color='#0080FF', height=5, aspect=2.0,\n",
        "              order=['Monday','Tuesday','Wednesday','Thursday','Saturday','Sunday']\n",
        "              #order=['0h','1h','2h','3h','4h','5h','6h','7h','8h','9h','10h','11h','12h',\n",
        "              #'13h','14h','15h','16h','17h','18h','19h','20h','21h','22h','23h']) #'#0080FF', '#070707', '#454545'\n",
        "  )\n",
        "  plt.title(f'Events by {Time_column}')\n",
        "  #plt.axhline(y=43, color='red', label='avg_week')\n",
        "  #plt.legend(bbox_to_anchor = (1.1, 1), loc = 'upper center')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "tL7ZieQNslIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Interacting with list of columns\n",
        "@interact(Nace = df1['market_nace_main_desc'].unique().tolist(), Variable = custom_list_2)\n",
        "def visualize_nace(Nace, Variable):\n",
        "  df = df1[df1['market_nace_main_desc']==Nace].copy()\n",
        "  df = df.groupby(by=['market_nace_main_desc','county']).agg(avg = (Variable,'mean')).reset_index()\n",
        "  fig_x, axes = plt.subplots(1, 1, figsize=(7.5, 5.5))\n",
        "  axes.set_title(f'{Nace}: {Variable}')\n",
        "  sns.barplot(x='market_nace_main_desc', y='avg', data=df, hue='county', palette='tab20', ax=axes)\n",
        "  plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "dIrCE0p2SpVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggregating Data"
      ],
      "metadata": {
        "id": "bONB0yDOpegD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting columns for aggregation\n",
        "custom_list_2 = ['', '', '', ''] # => Add column names for slicing here."
      ],
      "metadata": {
        "id": "NNoCs4zwplwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main data aggregation\n",
        "df1_a = df1.groupby(by=custom_list_2, dropna=False).agg(CHURN_COUNT = ('CUSTOMER_ID', 'count')).reset_index() # => Note: Dropna=False to avoid dropping data if group keys contain NA values."
      ],
      "metadata": {
        "id": "fkRYz8ZiULYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating list of aggregated fields\n",
        "df1_list = [(pd.DataFrame(df1[i].value_counts(dropna=False))) for i in custom_list_1]"
      ],
      "metadata": {
        "id": "0V36296QXe5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exporting results to local drive"
      ],
      "metadata": {
        "id": "RF8TokG_-W7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting main excel file\n",
        "with pd.ExcelWriter('script_20230417.xlsx', engine='openpyxl') as writer:\n",
        "  df2.to_excel(writer, sheet_name='Sheet1', index=False)\n",
        "files.download('script_20230417.xlsx')"
      ],
      "metadata": {
        "id": "sPlkPCjpeybu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting list of excel sheets\n",
        "with pd.ExcelWriter('Script_202208221130.xlsx', engine='openpyxl') as writer:\n",
        "  for i in range(len(df1_list)-1):\n",
        "    df1_list[i].to_excel(writer, sheet_name=f'{df1_list[i].columns[0]}', index=True)\n",
        "files.download('Script_202208221130.xlsx')"
      ],
      "metadata": {
        "id": "ZA02I_Wf-W7T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}