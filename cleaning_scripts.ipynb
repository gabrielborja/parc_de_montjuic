{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "bONB0yDOpegD",
        "RF8TokG_-W7T"
      ],
      "authorship_tag": "ABX9TyOsxqQo3/z6tIUetqFBFeaz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabrielborja/parc_de_montjuic/blob/main/cleaning_scripts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cleaning scripts"
      ],
      "metadata": {
        "id": "lStUu_NOrzIt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libraries"
      ],
      "metadata": {
        "id": "YleVYZS5sBdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upgrade Matplotlib\n",
        "!pip install matplotlib --upgrade\n",
        "#!pip install plotly --upgrade"
      ],
      "metadata": {
        "id": "o6NPkjW-m7mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGeTJjgpsBdW"
      },
      "outputs": [],
      "source": [
        "# Importing python libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "#from geopy.geocoders import Nominatim\n",
        "from ipywidgets import interact"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Data"
      ],
      "metadata": {
        "id": "n_NDy1jtsBdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading data from local drive\n",
        "from google.colab import files\n",
        "uploaded1 = files.upload()"
      ],
      "metadata": {
        "id": "O7uOQYmTsBdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing loaded data from excel to a pandas dataframe\n",
        "import io\n",
        "df1 = pd.read_excel(io.BytesIO(uploaded1['05_hline.xlsx']))"
      ],
      "metadata": {
        "id": "1DSSEUWrsBdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing loaded data from csv to a pandas dataframe\n",
        "#import io\n",
        "#df1 = pd.read_csv(io.BytesIO(uploaded1['20230504mdrift.csv']), sep='|', engine='python')#, encoding='latin-1')\n",
        "#quotechar='\"', on_bad_lines=False)"
      ],
      "metadata": {
        "id": "sW7oVve_ggcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modifying columns to lower case\n",
        "df1.rename(columns={i:i.lower() for i in df1.columns}, inplace=True)"
      ],
      "metadata": {
        "id": "kGPBKIADjT94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.rename(columns={'operator_in_commercial_name':'operator_in'}, inplace=True)"
      ],
      "metadata": {
        "id": "eqIYosRidcMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking dataframe info\n",
        "pd.DataFrame(df1.info())"
      ],
      "metadata": {
        "id": "3bYk72_tfjYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning Data"
      ],
      "metadata": {
        "id": "B4lTGJ3exux6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pd.concat(pd.DataFrame(df1.dtypes),df1.count())\n",
        "df1.dtypes\n",
        "#pd.concat(df1.dtypes, df1.count())\n",
        "#df1.count()\n",
        "#pd.concat()"
      ],
      "metadata": {
        "id": "CuxwzcnHgXus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parsing object column to datetime\n",
        "#df1['inserted_date'] = pd.to_datetime(df1['inserted_date']) #format='m%/%d/%Y %I:%M:%S %p')\n",
        "\n",
        "date_col = 'order_updated' #-> Change to the desired column\n",
        "def parse_datetime(date_col):\n",
        "  df1[date_col] = pd.to_datetime(df1[date_col], format='%Y-%m-%d %H:%M:%S.%f')\n",
        "\n",
        "parse_datetime(date_col)"
      ],
      "metadata": {
        "id": "S6bHev7HPrSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting year, month, day of the week, hour and date categories\n",
        "\n",
        "date_col = 'timestamp' #-> Change to the desired column\n",
        "def extract_datetime(df, date_col):\n",
        "  df = df.assign(year = df[date_col].dt.year,\n",
        "                 month = df[date_col].dt.month_name(),\n",
        "                 weeknum = df[date_col].dt.isocalendar().week,\n",
        "                 week_of_year = 'w' + df[date_col].dt.isocalendar().week.astype(str),\n",
        "                 day_of_week = df[date_col].dt.day_name(),\n",
        "                 hour = df[date_col].dt.hour.astype(str) + 'h',\n",
        "                 hour_of_day = df[date_col].dt.hour)\n",
        "  return df\n",
        "\n",
        "df1 = extract_datetime(df1, date_col)"
      ],
      "metadata": {
        "id": "IQJGJt9NrOaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting latitud and longitud from city names\n",
        "def extract_lat_and_lon(df):\n",
        "  geolocator = Nominatim(user_agent=\"MyApp\")\n",
        "  cities = sorted([i for i in set(df1['municipality'])])\n",
        "  ci_lat = {}\n",
        "  ci_lon = {}\n",
        "  for i in cities:\n",
        "    location = geolocator.geocode(i)\n",
        "    ci_lat.update({i:location.latitude})\n",
        "    ci_lon.update({i:location.longitude})\n",
        "  #ci_lat = {i: geolocator.geocode(i).latitude for i in cities}\n",
        "  #ci_lon = {i: geolocator.geocode(i).longitude for i in cities}\n",
        "  df = df.assign(lat = df['municipality'].replace(to_replace=ci_lat),\n",
        "                 lon = df['municipality'].replace(to_replace=ci_lon)\n",
        "                 )\n",
        "  return df\n",
        "  #return {i: (geolocator.geocode(i).latitude, geolocator.geocode(i).longitude) for i in my_list}\n",
        "\n",
        "df1 = extract_lat_and_lon(df1)\n",
        "df1.tail()"
      ],
      "metadata": {
        "id": "6OLxH7rTzABh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning invalid orgnum\n",
        "org_col = 'customer_orgnumber' #-> Change to the desired column\n",
        "def check_valid_org_num(df):\n",
        "  df = df.assign(org_check = np.where(df['org_col'].isnull(), 'Wrong',\n",
        "                             np.where(df['org_col'].str.len()>9, 'Wrong',\n",
        "                             np.where(df['org_col'].str.match(r'\\d{9}'),'Valid','Wrong'))))\n",
        "  return df\n",
        "\n",
        "df1 = check_valid_org_num(df1)"
      ],
      "metadata": {
        "id": "HjBVQ-SxXmC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flattening list of list and extracting unique valid IDs from column\n",
        "def extract_valid_ids(df, column_name):\n",
        "  temp1 = [list(json.loads(i).items()) for i in df[column_name]]\n",
        "  temp2 = [i for x in temp1 for i in x]\n",
        "  temp3 = [i[1] for i in temp2 if i[0] == 'naviIdIfMinBedrift']\n",
        "  flat = list(set(temp3))\n",
        "  f_df = pd.DataFrame(flat, columns=['valid_id']).sort_values(by='valid_id').reset_index(drop=True)\n",
        "  return f_df\n",
        "  #flat = [i for x in temp1 for i in x]\n",
        "  #set(flat)\n",
        "\n",
        "df2 = extract_valid_ids(df1,'custom_dimensions')\n",
        "df2.head()"
      ],
      "metadata": {
        "id": "kilsD4mR3kbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforming nace code\n",
        "df1 = df1.assign(market_nace_main_desc = df1['nace_main_desc'].str[:25])"
      ],
      "metadata": {
        "id": "alye0oMo-MXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing county\n",
        "df1 = df1.assign(county = df1['county'].str[:16])"
      ],
      "metadata": {
        "id": "CU4FtNhjY6Y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning brand preference\n",
        "df1 = df1.assign(brand = np.where(df1['terminal_name'].str.contains('iPhone'),'Apple',\n",
        "                                  np.where(df1['terminal_name'].str.contains('Samsung'),'Samsung', 'Other')))"
      ],
      "metadata": {
        "id": "evwHNJ0CNuYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating categorical orgnum column\n",
        "df1 = df1.assign(org_num = 'ORG' + df1['organization_number'].astype(str))"
      ],
      "metadata": {
        "id": "wfrUWtgnQGSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating time of day column\n",
        "df1 = df1.assign(time_of_day = np.where(df1['hr']<=11,'Morning',np.where(df1['hr']<=14,'Lunch','Afternoon')))"
      ],
      "metadata": {
        "id": "ex3vV1iaq1Il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Customizing terminal categories\n",
        "df1 = df1.assign(product_choice = np.where(df1['product_name'].str.contains('iPhone 11'),'iPhone 11',\n",
        "                                           np.where(df1['product_name'].str.contains('iPhone 12'),'iPhone 12',\n",
        "                                                    np.where(df1['product_name'].str.contains('iPhone 13'),'iPhone 13',\n",
        "                                                             np.where(df1['product_name'].str.contains('iPhone 14'),'iPhone 14',\n",
        "                                                                      np.where(df1['product_name'].str.contains('OnePlus'),'OnePlus',\n",
        "                                                                               'Samsung'))))))"
      ],
      "metadata": {
        "id": "0CWjDUwKwD8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the dataframe tail\n",
        "df1.tail(1)"
      ],
      "metadata": {
        "id": "cpao-slIUtMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['terminal_5g_device'] = df1['terminal_5g_device'].astype('str')"
      ],
      "metadata": {
        "id": "xvhd7p73X6wY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting categorical and numeric columns for EDA\n",
        "custom_list_1 = df1.select_dtypes(include=['object']).copy().columns.tolist()\n",
        "custom_list_2 = [i for i in df1.select_dtypes(include=['float64','int64']).copy().columns.tolist() if '_id' not in i]"
      ],
      "metadata": {
        "id": "pRuAqjseVzTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[i for i in df1.select_dtypes(include=['float64','int64']).copy().columns.tolist() if '_id' not in i]"
      ],
      "metadata": {
        "id": "g0aFLdjBZOec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"-\".join([i[0:2] for i in df1['nace_main'][0].split(' ')])"
      ],
      "metadata": {
        "id": "EfnC1YGI3Kq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1[df1['org_check']=='Valid'][['inserted_date','customer_orgnumber','org_check']].reset_index()"
      ],
      "metadata": {
        "id": "I3rzGwUIOUvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Temp1: Slicing dataframe \n",
        "df2 = df1[['orderid','statustext','username','listname','inserted_date','customer_orgnumber','customer_company',\n",
        "'customer_phone','customer_cellphone','customer_email','accept_date','productname','nummer som skal benytte',\n",
        "'orderproductsquantity','productquantity','year','month','weeknum','day','hour','hr','org_check']].copy()\n",
        "df2 = df2[df2['org_check']=='Valid'].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "B--ctk6iaz7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.rename( columns={'client_country_or_region':'country'}, inplace=True)"
      ],
      "metadata": {
        "id": "A2YkTBcVGTvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['custom_dimensions'][5]"
      ],
      "metadata": {
        "id": "0KgQPNIl1IAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df1[(df1['loyalty_flag']=='Yes')].reset_index(drop=True).copy()"
      ],
      "metadata": {
        "id": "3udU4IyQQg-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.tail()"
      ],
      "metadata": {
        "id": "l5GLezb0Q4hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring Data"
      ],
      "metadata": {
        "id": "0xEkdt6DUMnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying less rows in aggregations\n",
        "pd.options.display.max_rows = 15\n",
        "pd.options.display.min_rows = 10"
      ],
      "metadata": {
        "id": "Ltt9IWJgGLnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploring list of categorical columns with value counts\n",
        "#segm_list = ['Smartphone','Mobile broadband','Machine to machine']\n",
        "@interact(Column_name=custom_list_1, Percentage=[True, False])\n",
        "def explore_value_counts(Column_name, Percentage):\n",
        "  if Percentage == True:\n",
        "    df = df1.value_counts(subset=[Column_name], normalize=Percentage, dropna=False).reset_index(name='percent')\n",
        "    df = df.assign(percent = round(df['percent'],6)*100)\n",
        "    df = df.assign(cum_perc = df['percent'].cumsum())\n",
        "    df = df.assign(percent = df['percent'].round(2).astype(str) + '%')\n",
        "    df = df.assign(cum_perc = df['cum_perc'].round(2).astype(str) + '%')\n",
        "  else:\n",
        "    df = df1.value_counts(subset=[Column_name], normalize=Percentage, dropna=False).reset_index(name='events')\n",
        "    #df = df.sort_values(by=['events']).reset_index(drop=True)\n",
        "  return df"
      ],
      "metadata": {
        "id": "UGUH4IcP172y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploring list of categorical columns with value counts\n",
        "@interact(Categories=custom_list_1, Column_name=custom_list_2, Aggregate=['count','nunique','sum','mean','max','min'])\n",
        "def explore_numeric_columns(Categories, Column_name, Aggregate):\n",
        "  df = df1[df1['name']=='Performed'].groupby(by=Categories).agg(value=(Column_name,Aggregate)).reset_index()\n",
        "  df.rename(columns={'value':Column_name}, inplace=True)\n",
        "  df = df.sort_values(by=[Column_name],ascending=False).reset_index(drop=True)\n",
        "  return df"
      ],
      "metadata": {
        "id": "Yotbkx7R-0Zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting categorical columns with numeric columns\n",
        "agg_list = ['sum','mean','median','max','min','nunique','count']\n",
        "#segm_list = ['Smartphone','Mobile broadband','Machine to machine']\n",
        "@interact(Categories=['weeknum'], Column_name=custom_list_2[1:], Aggregate=agg_list)\n",
        "def visualize_two_columns(Categories, Column_name, Aggregate):\n",
        "  df = df1.groupby(by=[Categories]).agg(value=(Column_name,Aggregate)).reset_index()\n",
        "  df.rename(columns={'value':Column_name}, inplace=True)\n",
        "  df = df.sort_values(by=[Column_name],ascending=False).reset_index(drop=True)\n",
        "  #return df\n",
        "  fig_x, axes = plt.subplots(1, 1, figsize=(9.0, 4.0))\n",
        "  axes.set_title(f'MinBedrift - {Aggregate} of {Categories}')\n",
        "  sns.barplot(x=Categories, y=Column_name, data=df, estimator=Aggregate, order=[i for i in range(1,14)], color ='#0080FF',ax=axes)\n",
        "  for i in axes.containers:\n",
        "    axes.bar_label(i,fmt='%.f')\n",
        "  #plt.legend(title='Is_Loyal', bbox_to_anchor=(1.15, 1), loc=2, borderaxespad=0.)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "jZAXJd5tQR2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing histogram of numeric columns dynamically\n",
        "segm_list = ['Smartphone','Mobile broadband','Machine to machine']\n",
        "dis_list_1 =['count', 'frequency','probability', 'proportion', 'percent', 'density']\n",
        "@interact(Family=segm_list, Column=custom_list_2[2:], Graph_type=dis_list_1)\n",
        "def plot_histogram(Family, Column, Graph_type):\n",
        "  df = df1[df1['product_family']==Family].reset_index(drop=True).copy()\n",
        "  Q1 = df[Column].quantile(0.25)\n",
        "  Q3 = df[Column].quantile(0.75)\n",
        "  IQR = Q3 - Q1\n",
        "  df = df[(df[Column]>(Q1-1.5*IQR)) & (df[Column]<(Q3+1.5*IQR))].reset_index(drop=True)\n",
        "  fig_x, axes = plt.subplots(1, 1, figsize=(7.5, 3.5))\n",
        "  axes.set_title(f'{Family}: {Graph_type} - {Column}')\n",
        "  sns.histplot(x=Column, data=df, hue='loyalty_flag', stat=Graph_type, bins=15, \n",
        "               multiple='stack', palette={'Yes':'green','No':'#e49444'}, ax=axes)\n",
        "  for i in axes.containers:\n",
        "    axes.bar_label(i,fmt='%.2f')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "ccW7l0AJH2M-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing distribution of numeric columns dynamically\n",
        "segm_list = ['Smartphone','Mobile broadband','Machine to machine']\n",
        "dis_list_2 =['hist', 'kde','ecdf']\n",
        "@interact(Family=segm_list, Column=custom_list_2[2:], Graph_type=dis_list_2, Log_sc=[False,True])\n",
        "def plot_distribution(Family, Column, Graph_type, Log_sc):\n",
        "  df = df1[df1['product_family']==Family].reset_index(drop=True).copy()\n",
        "  Q1 = df[Column].quantile(0.25)\n",
        "  Q3 = df[Column].quantile(0.75)\n",
        "  IQR = Q3 - Q1\n",
        "  df = df[(df[Column]>(Q1-1.5*IQR)) & (df[Column]<(Q3+1.5*IQR))].reset_index(drop=True)\n",
        "  #sns.set(rc={'figure.figsize':(10,5)})\n",
        "  sns.displot(x=Column, data=df, hue='loyalty_flag', kind=Graph_type, log_scale=Log_sc, #multiple='stack',\n",
        "              palette={'Yes':'green','No':'#e49444'}, height=4.5, aspect=2) \n",
        "  plt.title(f'{Family} - {Column}')\n",
        "  plt.axhline(y=0.5, color='red', ls='--')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "UtqoJoogSJ6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing distribution of numeric columns dynamically\n",
        "segm_list = ['Smartphone','Mobile broadband','Machine to machine']\n",
        "@interact(Family=segm_list, X_col=custom_list_2[2:], Y_col=custom_list_1)\n",
        "def plot_boxplot(Family, X_col, Y_col):\n",
        "  df = df1[df1['product_family']==Family].reset_index(drop=True).copy()\n",
        "  Q1 = df[X_col].quantile(0.25)\n",
        "  Q3 = df[X_col].quantile(0.75)\n",
        "  IQR = Q3 - Q1\n",
        "  df = df[(df[X_col]>(Q1-1.5*IQR)) & (df[X_col]<(Q3+1.5*IQR))].reset_index(drop=True)\n",
        "  #sns.set(rc={'figure.figsize':(10,5)})\n",
        "  sns.boxplot(x=X_col, y=Y_col, data=df, hue='loyalty_flag', palette={'Yes':'green','No':'#e49444'})\n",
        "  plt.title(f'{X_col} - {Y_col}')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "AiiJ9bYYDayk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting pair plot of numeri variables \n",
        "segm_list = ['Smartphone','Mobile broadband','Machine to machine']\n",
        "hue_list = ['loyalty_flag']\n",
        "@interact(Family=segm_list, Column=custom_list_2[2:], Flag=hue_list)\n",
        "def plot_pairplot(Family, Column, Flag):\n",
        "  df = df1[df1['product_family']==Family].reset_index(drop=True).copy()\n",
        "  df = df[['product_family','loyalty_flag','lifetime_days','mb_total_l3m_avg','voice_total_l3m_avg','subscriber_profit']].copy()\n",
        "  sns.pairplot(data=df, hue=Flag)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "2ww1YmOaAovG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing scatterplot of numeric columns dynamically\n",
        "@interact(Column=custom_list_2)\n",
        "def visualize_numeric(Column):\n",
        "  # 'count', 'frequency','probability', 'proportion', 'percent', 'density'\n",
        "  Q1 = df1[Column].quantile(0.25)\n",
        "  Q3 = df1[Column].quantile(0.75)\n",
        "  IQR = Q3 - Q1\n",
        "  df = df1[(df1[Column]>(Q1-1.5*IQR)) & (df1[Column]<(Q3+1.5*IQR))].reset_index(drop=True)\n",
        "  #sns.set(rc={'figure.figsize':(10,5)})\n",
        "  sns.scatterplot(x='lifetime_days', y=Column, data=df, hue='loyalty_flag', style='loyalty_flag') #color='green' #binwidth=2\n",
        "  plt.title(f'Histogram - {Column}')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "tUGUyBturhuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing time columns\n",
        "@interact(Time_column=['month','week_of_year','day_of_week','hour'])\n",
        "def visualize_time_dimension(Time_column):\n",
        "  sns.catplot(x=Time_column, data=df1, kind='count', color='#0080FF', height=5, aspect=2.0,\n",
        "              order=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
        "              #order=['0h','1h','2h','3h','4h','5h','6h','7h','8h','9h','10h','11h','12h',\n",
        "              #'13h','14h','15h','16h','17h','18h','19h','20h','21h','22h','23h']) #'#0080FF', '#070707', '#454545'\n",
        "  )\n",
        "  plt.title(f'Events by {Time_column}')\n",
        "  #plt.axhline(y=43, color='red', label='avg_week')\n",
        "  #plt.legend(bbox_to_anchor = (1.1, 1), loc = 'upper center')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "tL7ZieQNslIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Interacting with list of columns\n",
        "@interact(Column_name = custom_list_1, Variable = custom_list_2)\n",
        "def visualize_nace(Nace, Variable):\n",
        "  df = df1[df1['market_nace_main_desc']==Nace].copy()\n",
        "  df = df.groupby(by=['market_nace_main_desc','county']).agg(avg = (Variable,'mean')).reset_index()\n",
        "  fig_x, axes = plt.subplots(1, 1, figsize=(7.5, 5.5))\n",
        "  axes.set_title(f'{Nace}: {Variable}')\n",
        "  sns.barplot(x='market_nace_main_desc', y='avg', data=df, hue='county', palette='tab20', ax=axes)\n",
        "  plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "dIrCE0p2SpVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggregating Data"
      ],
      "metadata": {
        "id": "bONB0yDOpegD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting columns for aggregation\n",
        "custom_list_2 = ['', '', '', ''] # => Add column names for slicing here."
      ],
      "metadata": {
        "id": "NNoCs4zwplwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main data aggregation\n",
        "df1_a = df1.groupby(by=custom_list_2, dropna=False).agg(CHURN_COUNT = ('CUSTOMER_ID', 'count')).reset_index() # => Note: Dropna=False to avoid dropping data if group keys contain NA values."
      ],
      "metadata": {
        "id": "fkRYz8ZiULYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating list of aggregated fields\n",
        "df1_list = [(pd.DataFrame(df1[i].value_counts(dropna=False))) for i in custom_list_1]"
      ],
      "metadata": {
        "id": "0V36296QXe5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exporting results to local drive"
      ],
      "metadata": {
        "id": "RF8TokG_-W7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting main excel file\n",
        "with pd.ExcelWriter('script_05.xlsx', engine='openpyxl') as writer:\n",
        "  df2.to_excel(writer, sheet_name='Sheet1', index=False)\n",
        "files.download('script_05.xlsx')"
      ],
      "metadata": {
        "id": "sPlkPCjpeybu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting list of excel sheets\n",
        "with pd.ExcelWriter('Script_202208221130.xlsx', engine='openpyxl') as writer:\n",
        "  for i in range(len(df1_list)-1):\n",
        "    df1_list[i].to_excel(writer, sheet_name=f'{df1_list[i].columns[0]}', index=True)\n",
        "files.download('Script_202208221130.xlsx')"
      ],
      "metadata": {
        "id": "ZA02I_Wf-W7T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}