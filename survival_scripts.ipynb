{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOtPYgjjefPLkpqTsDviGpy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabrielborja/parc_de_montjuic/blob/main/survival_scripts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Survival EDA"
      ],
      "metadata": {
        "id": "lStUu_NOrzIt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libraries"
      ],
      "metadata": {
        "id": "YleVYZS5sBdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Updating libraries version\n",
        "!pip install matplotlib --upgrade\n",
        "!pip install plotly --upgrade"
      ],
      "metadata": {
        "id": "H0T2EEwnrK38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGeTJjgpsBdW"
      },
      "outputs": [],
      "source": [
        "# Importing python libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "#import plotly.express as px\n",
        "from ipywidgets import interact"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Data"
      ],
      "metadata": {
        "id": "n_NDy1jtsBdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading data from local drive\n",
        "from google.colab import files\n",
        "uploaded1 = files.upload()"
      ],
      "metadata": {
        "id": "O7uOQYmTsBdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing loaded data from csv to a pandas dataframe\n",
        "import io\n",
        "df1 = pd.read_csv(io.BytesIO(uploaded1['Script_202209130729.csv']), sep='|', engine='python')"
      ],
      "metadata": {
        "id": "sW7oVve_ggcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chainging columns to lower case\n",
        "df1.rename(columns={i:i.lower() for i in df1.columns}, inplace=True)"
      ],
      "metadata": {
        "id": "kGPBKIADjT94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing geographic column to title case\n",
        "df1 = df1.assign(county_name = df1.loc[:,'county_name'].str[:15].str.title())"
      ],
      "metadata": {
        "id": "S0qtDOlBXQaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the dataframe info\n",
        "df1.info()"
      ],
      "metadata": {
        "id": "aeaClthP4mgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering"
      ],
      "metadata": {
        "id": "4fHpi8v-vnIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing dataframe according to dtype\n",
        "def slicing_by_dtypes():\n",
        "  ''' Creating subsets of the dataframe to separate between binary, float and categorical columns\n",
        "  Returns tuple with 3 dataframes split in the following order: binary, numeric and object '''\n",
        "  # Creating subset of binary columns\n",
        "  df_bin = df1.select_dtypes(include=['float64']).copy()\n",
        "  list_64 = []\n",
        "  [list_64.append(df_bin.loc[:,i]) for i in df_bin.columns if len(df_bin.loc[:,i].unique()) > 3]\n",
        "  [df_bin.drop(i, axis=1, inplace=True) for i in df_bin.columns if len(df_bin.loc[:,i].unique()) > 3]\n",
        "  # Creating subset of numeric columns\n",
        "  df_f64 = pd.concat(list_64, axis=1)\n",
        "  # Creating subset of object columns\n",
        "  df_obj = df1.select_dtypes(include=['object']).copy()\n",
        "  return (df_bin, df_f64, df_obj)\n",
        "\n",
        "df1_bi, df1_nu, df1_ob = slicing_by_dtypes()"
      ],
      "metadata": {
        "id": "o3GBKiXXBQeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking sliced dataframes info\n",
        "df1_bi.info()"
      ],
      "metadata": {
        "id": "fURjDaW6FnGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling NaN with 0 in binary columns\n",
        "values_bi = {i:0 for i in df1_bi.columns}\n",
        "df1_bi.fillna(value=values_bi, inplace=True)"
      ],
      "metadata": {
        "id": "tJaysI5MErgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating binary columns from numeric data\n",
        "for i in df1_nu.columns:\n",
        "  df1_bi[f'has_{i}'] = np.where(df1_nu.loc[:,i]>0,1,0)"
      ],
      "metadata": {
        "id": "7LgEub1APE32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling NaN with 'Unknown' object in categorical columns\n",
        "values_ob = {i:'Unknown' for i in df1_ob.columns}\n",
        "df1_ob.fillna(value=values_ob, inplace=True)"
      ],
      "metadata": {
        "id": "xWQIlCi-WeEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1_nu.info()"
      ],
      "metadata": {
        "id": "4sBClXWhQFSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenating binary and object dataframes\n",
        "df1_a = pd.concat([df1_ob, df1_bi, df1.loc[:,['churn','customer_churn']]], axis=1)"
      ],
      "metadata": {
        "id": "aFiq5TRrgTyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the cleaned dataframe info\n",
        "df1_a.info()"
      ],
      "metadata": {
        "id": "b73KqfHOZFAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring Data"
      ],
      "metadata": {
        "id": "0xEkdt6DUMnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploring list of columns with value counts\n",
        "@interact(Column_name=df1_a.columns[1:], Percentage=[True, False])\n",
        "def explore_value_counts(Column_name, Percentage):\n",
        "  df = df1_a.value_counts(subset=[Column_name], normalize=Percentage, dropna=False)\n",
        "  return df"
      ],
      "metadata": {
        "id": "dtUKhSZeq7CW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Describing each column\n",
        "@interact(Column_name=df1_a.columns)\n",
        "def explore_value_counts(Column_name):\n",
        "  return df1_a.loc[:,[Column_name]].describe()"
      ],
      "metadata": {
        "id": "f4BjWX7zsO6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploring number of categories in each categorical column\n",
        "for cat in df1_a.columns:\n",
        "  print(f'{cat} => {len(df1_a[cat].unique())}')"
      ],
      "metadata": {
        "id": "sGClpoFqOIpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Importance"
      ],
      "metadata": {
        "id": "9KoPLJaRfdHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating dummy variables from categorical columns\n",
        "col_enc = df1_ob.columns.tolist()\n",
        "df1_b = pd.get_dummies(df1_a, columns=col_enc)"
      ],
      "metadata": {
        "id": "DFZG_NWzfiRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1_b.info()"
      ],
      "metadata": {
        "id": "Z2gtDicxkVB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataframe into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = df1_b.drop(['churn', 'customer_churn'], axis='columns')\n",
        "y = df1_b.loc[:,'churn']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=17)"
      ],
      "metadata": {
        "id": "KQTabTOiloWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating a random forest model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "rf1 = RandomForestClassifier()\n",
        "rf1.fit(X_train, y_train)\n",
        "y_predict = rf1.predict(X_test)\n",
        "print(f'model accuracy : {round(accuracy_score(y_test, y_predict),4)}')"
      ],
      "metadata": {
        "id": "B_rKuBFJoq-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare response prediction = 1\n",
        "test = pd.DataFrame({'y-test': y_test, 'y-pred':y_predict})\n",
        "test[test['y-pred']==1]"
      ],
      "metadata": {
        "id": "E7000gDQslJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing Feature Importance\n",
        "df1_fi = pd.DataFrame(rf1.feature_importances_, index=X_train.columns,\n",
        "                      columns=['importance']).reset_index().sort_values('importance', ascending=False)\n",
        "df1_fi.rename(columns={'index':'variables'}, inplace=True)"
      ],
      "metadata": {
        "id": "1NMzA9Kfmghd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning categories to common features\n",
        "choice_list = ['commitment','on_net','volte','vowifi','fee','mb','topup','discount','lifetime','market_segment','phone','county','usage']\n",
        "cond_list = [df1_fi['variables'].str.contains(i) for i in choice_list]\n",
        "df1_fi = df1_fi.assign(category = np.select(cond_list, choice_list, 'other')).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "_i843NoezLEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregating common features\n",
        "df1_gr = df1_fi.groupby(by=['category']).agg(total_importance = ('importance', 'sum')).reset_index()\n",
        "df1_gr = df1_gr.sort_values(by='total_importance', ascending=False).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "kOX2sJ8O9eDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the final ranking of features by main category\n",
        "df1_gr"
      ],
      "metadata": {
        "id": "UDZiOMU69Ers"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploring feature importance\n",
        "@interact(Category=df1_gr['category'].unique())\n",
        "def explore_feature_importance(Category):\n",
        "  df = df1_fi[df1_fi['category'].str.contains(Category)]\n",
        "  df = df.assign(perc_total = round(df['importance']/(df['importance'].sum()),2))\n",
        "  return df"
      ],
      "metadata": {
        "id": "etfCqxmm_Noz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exporting results to local drive"
      ],
      "metadata": {
        "id": "RF8TokG_-W7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating current datetime\n",
        "from datetime import datetime\n",
        "file_name = 'feature_import_'\n",
        "file_name +=(datetime.now().strftime(\"%Y%m%d%H%M\"))\n",
        "file_name"
      ],
      "metadata": {
        "id": "Q2-D31L1SSB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting files to excel\n",
        "with pd.ExcelWriter(f'{file_name}.xlsx', engine='openpyxl') as writer:\n",
        "  df1_a.to_excel(writer, sheet_name='Sheet 1', index=False)\n",
        "files.download(f'{file_name}.xlsx')"
      ],
      "metadata": {
        "id": "9k5AleXiLFKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing Data"
      ],
      "metadata": {
        "id": "aDpSzJBsc4C_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing feature importance in two subplots\n",
        "#@interact(Category=df1_a.columns[1:-1])\n",
        "def plot_subplots(Category):\n",
        "  ''' Function for comparing two subplots '''\n",
        "  df = df1_a[df1_a['churn']==1].copy().loc[:,['period','churn',Category,'customer_churn']].reset_index()\n",
        "  #return df['period'][0]\n",
        "  fig_x, axes = plt.subplots(1, 2, figsize=(15.5, 6.5))\n",
        "  fig_x.suptitle(f'{Category}')\n",
        "  axes[0].set_title(f'{Category} vs. Customer churn - {df[\"period\"][0]}')\n",
        "  axes[1].set_title(f'{Category} vs. Turnover churn - {df[\"period\"][0]}')\n",
        "  sns.countplot(data=df[df['customer_churn']==1], x=Category, ax=axes[0])\n",
        "  sns.countplot(data=df[df['customer_churn']==0], x=Category, ax=axes[1])\n",
        "  for i in range(2):\n",
        "    for container in axes[i].containers:\n",
        "      axes[i].bar_label(container, fontsize=12)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "s-8xbONac5fQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploring feature importance in same graph\n",
        "@interact(Category=df1_a.columns[1:-2])\n",
        "def plot_feature(Category):\n",
        "  ''' Function for comparing total churn vs. customer churn in same graph '''\n",
        "  df = df1_a[df1_a['churn']==1].copy().loc[:,['period','churn',Category,'customer_churn']].reset_index(drop=True)\n",
        "  df = df.assign(churn_type = np.where(df['customer_churn']==1,'Customer','Turnover'))\n",
        "  data_order = sorted(df[Category].unique().tolist())\n",
        "  fig_x, axes = plt.subplots(1, 1, figsize=(7.5, 7.5))\n",
        "  axes.set_title(f'{Category}: Customer vs. Turnover churn - {df[\"period\"][0]}')\n",
        "  sns.countplot(data=df, y=Category, hue='churn_type', order=data_order, ax=axes)\n",
        "  for container in axes.containers:\n",
        "    axes.bar_label(container, fontsize=12)\n",
        "  #fig_x.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "  #plt.xticks(rotation=30)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "K2eUsYpKn7Th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Terminal"
      ],
      "metadata": {
        "id": "0Da9fz0eMqaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1_a = df1_a.assign(terminal_name = df1_a['terminal_name'].str.lower())"
      ],
      "metadata": {
        "id": "T7zncfweMpG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_list = ['iphone 4','iphone 5', 'iphone 6', 'iphone 7', 'iphone 8']\n",
        "cond_list = [df1_a['terminal_name'].str.contains(j) for j in check_list]\n",
        "choice_list = ['iphone 4','iphone 5', 'iphone 6', 'iphone 7', 'iphone 8']"
      ],
      "metadata": {
        "id": "O6423r6tOcF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cond_list[0].value_counts()"
      ],
      "metadata": {
        "id": "3P30GmPeQcHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1_a = df1_a.assign(terminal_type = np.select(cond_list, choice_list, 'other')).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "U0Keq3eEOURd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted([i for i in df1_a.terminal_name.unique().tolist() if 'iphone' in i])"
      ],
      "metadata": {
        "id": "mBYYgn7wL5S1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1_a.terminal_type.value_counts()"
      ],
      "metadata": {
        "id": "IPVa-71XRFoy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}